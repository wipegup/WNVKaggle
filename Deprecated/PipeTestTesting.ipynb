{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#class ChicagoPreprocessor(object):#\n",
    "#    def __init__(train, test = None):\n",
    "#        self.parkFinder =\n",
    "\n",
    "\n",
    "def agg_on_species(train, test):\n",
    "    \n",
    "    noAgg = [c for c in train.columns if c not in ['NumMosquitos','WnvPresent']]\n",
    "\n",
    "    agg = train.groupby(noAgg)['NumMosquitos', 'WnvPresent'].sum()\n",
    "\n",
    "    for i, c in enumerate(noAgg):\n",
    "        agg[c] = agg.index.map(lambda x:x[i])\n",
    "\n",
    "    agg.index = range(0,len(agg))\n",
    "    agg['WnvPresent'] = (agg['WnvPresent'].map(lambda x:x>0)).astype(int)\n",
    "    return agg, test\n",
    "\n",
    "def InitPrepross(train, test):\n",
    "\n",
    "    def location_add(df):\n",
    "        df['Location'] = [(df.loc[idx,'Longitude'], df.loc[idx, 'Latitude'])\n",
    "                            for idx in df.index]\n",
    "        return df\n",
    "\n",
    "    def change_date(df):\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def drop_unused(df):\n",
    "        for col in ['Address','Block','Street',\n",
    "              'AddressNumberAndStreet', 'AddressAccuracy',\n",
    "                    ]:\n",
    "            try:\n",
    "                df = df.drop(col, axis = 'columns')\n",
    "            except:\n",
    "                print(col, 'not present')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def species_dummies(df):\n",
    "        species = ['CULEX PIPIENS', 'CULEX PIPIENS/RESTUANS',\n",
    "                'CULEX RESTUANS', 'CULEX SALINARIUS',\n",
    "                'CULEX TERRITANS', 'CULEX TARSALIS',\n",
    "                 'CULEX ERRATICUS']\n",
    "        for s in species:\n",
    "            df[s] = (df['Species'] == s).astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform(df):\n",
    "        df = drop_unused(df)\n",
    "        df = location_add(df)\n",
    "        df = change_date(df)\n",
    "        df = species_dummies(df)\n",
    "        return df\n",
    "        \n",
    "    return transform(train), transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def WeatherProcess(train, test):\n",
    "\n",
    "def yeildWeather(target):\n",
    "    weather = pd.read_csv(target)\n",
    "    weather['Date'] = pd.to_datetime(weather['Date'])\n",
    "\n",
    "    toDrop = ['Depart', 'Depth','Water1',\n",
    "            'SnowFall', 'CodeSum', 'Heat',\n",
    "            'Cool', 'Sunrise']\n",
    "    weather = weather.drop(toDrop, axis=1)\n",
    "\n",
    "    toReplace = {'M':np.nan, '  T': 0.001, '-': '0000'}\n",
    "    for k in toReplace:\n",
    "        weather = weather.replace(k, toReplace[k])\n",
    "\n",
    "\n",
    "    toFloats = ['Tavg', 'WetBulb', 'PrecipTotal','StnPressure',\n",
    "                'SeaLevel', 'ResultSpeed','AvgSpeed']\n",
    "    for c in toFloats:\n",
    "        weather[c] = weather[c].astype(float)\n",
    "\n",
    "    weather['Sunset'] = [date\n",
    "                        if date[-2:] != '60'\n",
    "                        else str(int(date[0:2])+1)+'00'\n",
    "                        for date in weather['Sunset']]\n",
    "\n",
    "    weather['Sunset'] = pd.to_datetime(weather['Sunset'],\n",
    "                                        format=\"%H%M\")\n",
    "    weather.dropna(inplace=True)\n",
    "\n",
    "    return weather[weather['Station']== 1]\n",
    "\n",
    "def yeildAvgTemp(weather):\n",
    "    weather['Wk'] = weather['Date'].dt.week\n",
    "    weekTemp = pd.DataFrame(\n",
    "                    weather.groupby('Wk')['Tavg'].mean())\n",
    "    weekTemp['Week'] = weekTemp.index - 17\n",
    "    weekTemp['Week^2'] = weekTemp['Week']**2\n",
    "\n",
    "    lr = LinearRegression().fit(weekTemp.drop('Tavg', axis = 'columns'),\n",
    "                                weekTemp['Tavg'])\n",
    "    toRet = {}\n",
    "    for w in range(1,53):\n",
    "        toRet[w] = lr.intercept_ + (lr.coef_[0]*(w-17)) + (lr.coef_[1] * ((w-17)**2))\n",
    "\n",
    "    return toRet\n",
    "\n",
    "def calculate_agregate( weather_sub, avgTDict):\n",
    "    toRet = pd.Series()\n",
    "\n",
    "    allAgg = [np.max, np.min, np.mean]\n",
    "    toAgg = {'DewPoint': allAgg,\n",
    "            'StnPressure': allAgg,\n",
    "            'AvgSpeed': allAgg,\n",
    "            'Tmax':[np.max],\n",
    "            'Tmin':[np.min],\n",
    "            'Tavg':[np.mean],\n",
    "            'PrecipTotal':[np.sum, np.mean]\n",
    "            }\n",
    "    for k in toAgg:\n",
    "        for f in toAgg[k]:\n",
    "            toRet.loc[k + str(f).split(' ')[1]] = f(weather_sub[k])\n",
    "\n",
    "    finalEntry = weather_sub.iloc[len(weather_sub)-1]\n",
    "\n",
    "    toRet['temp_expected'] = avgTDict[pd.to_datetime(finalEntry['Date']).week]\n",
    "    toRet['temp_diff'] = toRet['Tavgmean'] - toRet['temp_expected']\n",
    "\n",
    "    sunset = finalEntry['Sunset']\n",
    "    toRet['sunset'] = sunset.hour + (sunset.minute / 60)\n",
    "\n",
    "    return toRet\n",
    "\n",
    "def date_ranges(dates):\n",
    "    uniqueYears = set([pd.to_datetime(d).year for d in dates])\n",
    "\n",
    "    dates = sorted(dates)\n",
    "    fyear = []\n",
    "    for y in uniqueYears:\n",
    "        for d in dates:\n",
    "            if pd.to_datetime(d).year == y:\n",
    "                print(d)\n",
    "                fyear.append(d)\n",
    "                break\n",
    "\n",
    "    for d in fyear:\n",
    "        dates = np.insert(dates, 0, d - pd.Timedelta(days = 8))\n",
    "        \n",
    "    dateRanges = []\n",
    "    for i in range(len(dates)-1):\n",
    "        if pd.to_datetime(dates[i]).year == pd.to_datetime(dates[i+1]).year:\n",
    "            dateRanges.append( (dates[i], dates[i+1]) )\n",
    "\n",
    "    return dateRanges\n",
    "\n",
    "def subset_weather(dateRange, weather):\n",
    "    mask = (weather['Date']>dateRange[0]) & (weather['Date'] <= dateRange[1])\n",
    "    return weather.loc[mask]\n",
    "\n",
    "def TWeatherDFMaker(dct):\n",
    "    toRet = pd.DataFrame().from_dict(dct)\n",
    "    toRet = toRet.transpose()\n",
    "    toRet.index = [idx for idx in toRet.index]\n",
    "    toRet['Trap'] = toRet.index.map(lambda x: x[0])\n",
    "    toRet['Date'] = toRet.index.map(lambda x: x[1])\n",
    "    toRet.index = range(len(toRet))\n",
    "\n",
    "    return toRet\n",
    "\n",
    "def trap_agregator(trap_df, weather, avgTDict):\n",
    "    trapWeather = {}\n",
    "    trap = trap_df['Trap'].iloc[0]\n",
    "\n",
    "    dates = trap_df['Date'].unique()\n",
    "    dates = sorted(dates)\n",
    "\n",
    "    dateRanges = date_ranges(dates)\n",
    "\n",
    "    for dr in dateRanges:\n",
    "        weather_sub = subset_weather(dr, weather)\n",
    "        trapWeather[(trap, dr[1])] = calculate_agregate(weather_sub, avgTDict)\n",
    "    toRet = pd.DataFrame().from_dict(trapWeather)\n",
    "\n",
    "    return TWeatherDFMaker(trapWeather)\n",
    "\n",
    "def transform(df):\n",
    "    observations = []\n",
    "\n",
    "    traps = df['Trap'].unique()\n",
    "    for t in traps:\n",
    "        observations.append(trap_agregator(df[df['Trap'] == t],\n",
    "        weather, avgTDict))\n",
    "    toRet = pd.concat(observations, axis = 'rows')\n",
    "\n",
    "    return toRet\n",
    "\n",
    "weatherTarget = './input/weather.csv'\n",
    "weather = yeildWeather(weatherTarget)\n",
    "avgTDict = yeildAvgTemp(weather)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-06-11T00:00:00.000000000\n",
      "2010-06-02T00:00:00.000000000\n",
      "2012-06-08T00:00:00.000000000\n",
      "2014-06-05T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "calcd = trap_agregator(test[test['Trap'] == 'T002'], weather, avgTDict).Date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reald = test[test['Trap']== 'T002'].Date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2008-06-11T00:00:00.000000000', '2008-06-17T00:00:00.000000000',\n",
       "       '2008-06-24T00:00:00.000000000', '2008-07-01T00:00:00.000000000',\n",
       "       '2008-07-04T00:00:00.000000000', '2008-07-11T00:00:00.000000000',\n",
       "       '2008-07-14T00:00:00.000000000', '2008-07-21T00:00:00.000000000',\n",
       "       '2008-07-23T00:00:00.000000000', '2008-07-24T00:00:00.000000000',\n",
       "       '2008-07-28T00:00:00.000000000', '2008-07-29T00:00:00.000000000',\n",
       "       '2008-08-04T00:00:00.000000000', '2008-08-05T00:00:00.000000000',\n",
       "       '2008-08-12T00:00:00.000000000', '2008-08-13T00:00:00.000000000',\n",
       "       '2008-08-19T00:00:00.000000000', '2008-08-25T00:00:00.000000000',\n",
       "       '2008-08-26T00:00:00.000000000', '2008-09-02T00:00:00.000000000',\n",
       "       '2008-09-03T00:00:00.000000000', '2008-09-09T00:00:00.000000000',\n",
       "       '2008-09-15T00:00:00.000000000', '2008-09-19T00:00:00.000000000',\n",
       "       '2008-09-29T00:00:00.000000000', '2010-06-02T00:00:00.000000000',\n",
       "       '2010-06-11T00:00:00.000000000', '2010-06-18T00:00:00.000000000',\n",
       "       '2010-06-25T00:00:00.000000000', '2010-06-28T00:00:00.000000000',\n",
       "       '2010-07-01T00:00:00.000000000', '2010-07-02T00:00:00.000000000',\n",
       "       '2010-07-12T00:00:00.000000000', '2010-07-13T00:00:00.000000000',\n",
       "       '2010-07-16T00:00:00.000000000', '2010-07-19T00:00:00.000000000',\n",
       "       '2010-07-23T00:00:00.000000000', '2010-07-26T00:00:00.000000000',\n",
       "       '2010-07-29T00:00:00.000000000', '2010-07-30T00:00:00.000000000',\n",
       "       '2010-08-05T00:00:00.000000000', '2010-08-06T00:00:00.000000000',\n",
       "       '2010-08-13T00:00:00.000000000', '2010-08-19T00:00:00.000000000',\n",
       "       '2010-08-20T00:00:00.000000000', '2010-08-26T00:00:00.000000000',\n",
       "       '2010-08-27T00:00:00.000000000', '2010-09-02T00:00:00.000000000',\n",
       "       '2010-09-10T00:00:00.000000000', '2010-09-13T00:00:00.000000000',\n",
       "       '2010-09-16T00:00:00.000000000', '2010-09-17T00:00:00.000000000',\n",
       "       '2010-09-23T00:00:00.000000000', '2010-09-24T00:00:00.000000000',\n",
       "       '2010-10-01T00:00:00.000000000', '2012-06-08T00:00:00.000000000',\n",
       "       '2012-06-15T00:00:00.000000000', '2012-06-21T00:00:00.000000000',\n",
       "       '2012-06-29T00:00:00.000000000', '2012-07-09T00:00:00.000000000',\n",
       "       '2012-07-13T00:00:00.000000000', '2012-07-19T00:00:00.000000000',\n",
       "       '2012-07-20T00:00:00.000000000', '2012-07-27T00:00:00.000000000',\n",
       "       '2012-08-03T00:00:00.000000000', '2012-08-09T00:00:00.000000000',\n",
       "       '2012-08-10T00:00:00.000000000', '2012-08-16T00:00:00.000000000',\n",
       "       '2012-08-17T00:00:00.000000000', '2012-08-23T00:00:00.000000000',\n",
       "       '2012-08-24T00:00:00.000000000', '2012-08-30T00:00:00.000000000',\n",
       "       '2012-08-31T00:00:00.000000000', '2012-09-10T00:00:00.000000000',\n",
       "       '2012-09-13T00:00:00.000000000', '2012-09-20T00:00:00.000000000',\n",
       "       '2012-09-28T00:00:00.000000000', '2014-06-05T00:00:00.000000000',\n",
       "       '2014-06-12T00:00:00.000000000', '2014-06-19T00:00:00.000000000',\n",
       "       '2014-06-26T00:00:00.000000000', '2014-07-03T00:00:00.000000000',\n",
       "       '2014-07-10T00:00:00.000000000', '2014-07-17T00:00:00.000000000',\n",
       "       '2014-07-24T00:00:00.000000000', '2014-07-31T00:00:00.000000000',\n",
       "       '2014-08-07T00:00:00.000000000', '2014-08-14T00:00:00.000000000',\n",
       "       '2014-08-21T00:00:00.000000000', '2014-08-28T00:00:00.000000000',\n",
       "       '2014-09-05T00:00:00.000000000', '2014-09-11T00:00:00.000000000',\n",
       "       '2014-09-18T00:00:00.000000000', '2014-09-25T00:00:00.000000000',\n",
       "       '2014-10-02T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-06-02T00:00:00.000000000\n",
      "2012-06-08T00:00:00.000000000\n",
      "2014-06-05T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "for rd in reald:\n",
    "    if rd in calcd:\n",
    "        pass\n",
    "    else:\n",
    "        print(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv', index_col= 0)\n",
    "\n",
    "train, test = InitPrepross(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 116293 entries, 1 to 116293\n",
      "Data columns (total 13 columns):\n",
      "Date                      116293 non-null datetime64[ns]\n",
      "Species                   116293 non-null object\n",
      "Trap                      116293 non-null object\n",
      "Latitude                  116293 non-null float64\n",
      "Longitude                 116293 non-null float64\n",
      "Location                  116293 non-null object\n",
      "CULEX PIPIENS             116293 non-null int32\n",
      "CULEX PIPIENS/RESTUANS    116293 non-null int32\n",
      "CULEX RESTUANS            116293 non-null int32\n",
      "CULEX SALINARIUS          116293 non-null int32\n",
      "CULEX TERRITANS           116293 non-null int32\n",
      "CULEX TARSALIS            116293 non-null int32\n",
      "CULEX ERRATICUS           116293 non-null int32\n",
      "dtypes: datetime64[ns](1), float64(2), int32(7), object(3)\n",
      "memory usage: 14.3+ MB\n"
     ]
    }
   ],
   "source": [
    "t2 = test\n",
    "t2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "wtr, wte = WeatherProcess(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10506, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4343, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wtr.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
