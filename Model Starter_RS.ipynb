{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building Starter\n",
    "\n",
    "Below are all the relevant dataframes\n",
    "\n",
    "Only thing that remains to be done is aggregate for when there are multiple observations for a single trap/day/species  \n",
    "\n",
    "\n",
    "`df_w` include all the aggregated weather  \n",
    "`df_a` includes weather and park/water data (note park/water data are svd features  \n",
    "`df_s` includes all the spray data (so only years 2011/13) with categorically encoded \"spray before\" and \"spray after\" Variables  \n",
    "\n",
    "\n",
    "No train/test splits have been done, but what we discussed was as standard train/test split for the spray data, and 4-fold CV for the other data, split by year (there is a 'yr' column in the dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open('allDF.pickle','rb') as f:\n",
    "    allDF = pickle.load(f)\n",
    "    \n",
    "df_w = allDF[0]\n",
    "df_a = allDF[1]\n",
    "df_s = allDF[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NumMosquitos', 'WnvPresent', 'Date', 'Species', 'Trap', 'Latitude',\n",
       "       'Longitude', 'Yr', 'Mo', 'Week', 'Location', 'CULEX PIPIENS',\n",
       "       'CULEX PIPIENS/RESTUANS', 'CULEX RESTUANS', 'CULEX SALINARIUS',\n",
       "       'CULEX TERRITANS', 'CULEX TARSALIS', 'CULEX ERRATICUS', 'DewPointamax',\n",
       "       'DewPointamin', 'DewPointmean', 'StnPressureamax', 'StnPressureamin',\n",
       "       'StnPressuremean', 'AvgSpeedamax', 'AvgSpeedamin', 'AvgSpeedmean',\n",
       "       'temp_max', 'temp_min', 'temp_avg', 'temp_expected', 'temp_diff',\n",
       "       'sunset', 'precip_total', 'precip_avg', 'Park0', 'Park1', 'Park2',\n",
       "       'Park3', 'Park4', 'Park5', 'Water0', 'Water1', 'Water2', 'Water3',\n",
       "       'Water4', 'Water5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = df[df['Yr']==2009]\n",
    "train = df[df['Yr']!= 2009]\n",
    "\n",
    "y_train = train['WnvPresent']\n",
    "y_test = test['WnvPresent']\n",
    "\n",
    "toDrop = ['Date','WnvPresent','Location','NumMosquitos', 'Species','Trap','Location','Yr',\n",
    "          #'Date_end',\n",
    "          #'DewPointamax', 'DewPointamin','temp_max', 'temp_min',\n",
    "          #'Park0', 'Park1', 'Park2','Park3', 'Park4', 'Park5', \n",
    "          #'Water0', 'Water1', 'Water2', 'Water3','Water4', 'Water5'\n",
    "         ]\n",
    "X_train0 = train.drop(toDrop, axis = 'columns')\n",
    "#X_train = X_train.iloc[:,4:] # dropping species, trap, date\n",
    "X_test0 = test.drop(toDrop, axis = 'columns')\n",
    "#X_test = X_test.iloc[:,4:] # dropping species, trap, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = ss.fit_transform(X_train0)\n",
    "X_test = ss.transform(X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "\n",
    "def best_model(model_list, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Runs a randomized search of 10 iters, and strat-kfold cv\n",
    "    And produces a list of classifiers - parameters - scores\n",
    "    for the best of each type of model\n",
    "    \n",
    "    To change it to ONLY spit out the best model, replace \n",
    "    \n",
    "    'return classifier' \n",
    "    \n",
    "    for\n",
    "    \n",
    "    'return best_classifier[1]'\n",
    "    \"\"\"\n",
    "    best_score = 0.0\n",
    "    best_classifier = None\n",
    "    classifiers = []\n",
    "    for name, model, parameters in model_list:\n",
    "        classifiers.append(best_config(name, model, parameters,\n",
    "                                       X_train,\n",
    "                                       y_train))\n",
    " \n",
    "    for name, score, classifier in classifiers:\n",
    "        if (score > best_score):\n",
    "            best_score = score\n",
    "            best_classifier = [name, classifier]\n",
    "    return classifiers\n",
    "\n",
    "def best_config(name, model, parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    A simple GridSearch \n",
    "    Requires: model, parameters, X & y variables\n",
    "    +\n",
    "    \"\"\"\n",
    "    k = StratifiedKFold(n_splits=5)\n",
    "    print(\"Searching \"+str(name))\n",
    "    clf = RandomizedSearchCV(model, parameters[0], cv=k, \n",
    "                            n_iter=15, verbose=1, \n",
    "                             n_jobs=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Finished \"+str(name))\n",
    "    print('')\n",
    "    return [str(clf.best_params_), \n",
    "            clf.best_score_, \n",
    "            clf.best_estimator_]\n",
    "\n",
    "def model_list():\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a list of models & params,\n",
    "    Add more manually, for more options\n",
    "    gb = GradientBoostingClassifier()\n",
    "    rf = RandomForestClassifier()\n",
    "    bg = BaggingClassifier()\n",
    "    ad = AdaBoostClassifier()\n",
    "    knn = KNeighborsClassifier()\n",
    "    \"\"\"\n",
    "    \n",
    "    models = []    \n",
    "\n",
    "    #gradient\n",
    "    gb_tuned_parameters = [{\"n_estimators\": [50, 75, 100, 150, 200, 250],\n",
    "                           'learning_rate' : [0.05, 0.1, 0.2], \n",
    "                            'min_samples_split' : [2, 3, 4], \n",
    "                            'max_depth' : [2, 3, 4, 5]}]\n",
    "    models.append(['GB', GradientBoostingClassifier(), gb_tuned_parameters])\n",
    " \n",
    "    #random forest\n",
    "    rf_tuned_parameters = [{\"max_depth\": [None, 2, 3, 4, 5],\n",
    "                           'criterion' : ['gini'], \n",
    "                            'min_samples_split' : [2, 3, 4], \n",
    "                            'min_samples_leaf' : [1, 2, 3]}]\n",
    "    models.append([\"RandomForest\",RandomForestClassifier(n_jobs=-1),rf_tuned_parameters])\n",
    "\n",
    "    #Bagged\n",
    "    bg_tuned_parameters = [{\"n_estimators\": [x for x in range(2,20)]}]\n",
    "    models.append(['BG', BaggingClassifier(), bg_tuned_parameters])\n",
    "\n",
    "    #Ada Model\n",
    "    ad_tuned_parameters = [{\"n_estimators\": [x for x in range(2,20)]}]\n",
    "    models.append(['AD', AdaBoostClassifier(), ad_tuned_parameters])\n",
    "    \n",
    "    #kNN Model\n",
    "    knn_tuned_parameters = [{\"n_neighbors\": [1, 3, 5, 10, 20], \n",
    "                             'weights':['uniform','distance'],\n",
    "                            'metric':['euclidean','manhattan']}]\n",
    "    models.append([\"kNN\", KNeighborsClassifier(),knn_tuned_parameters])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching GB\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=2)]: Done  75 out of  75 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished GB\n",
      "\n",
      "Searching RandomForest\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=2)]: Done  75 out of  75 | elapsed:   13.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished RandomForest\n",
      "\n",
      "Searching BG\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=2)]: Done  75 out of  75 | elapsed:   13.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished BG\n",
      "\n",
      "Searching AD\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  72 out of  75 | elapsed:    4.9s remaining:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done  75 out of  75 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished AD\n",
      "\n",
      "Searching kNN\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   35.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished kNN\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  75 out of  75 | elapsed:   56.3s finished\n"
     ]
    }
   ],
   "source": [
    "GS_model = best_model(model_list(),X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"{'n_estimators': 200, 'min_samples_split': 3, 'max_depth': 2, 'learning_rate': 0.05}\",\n",
       "  0.8914634146341464,\n",
       "  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.05, loss='deviance', max_depth=2,\n",
       "                max_features=None, max_leaf_nodes=None,\n",
       "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                min_samples_leaf=1, min_samples_split=3,\n",
       "                min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "                warm_start=False)],\n",
       " [\"{'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': 3, 'criterion': 'gini'}\",\n",
       "  0.9332317073170732,\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=2, min_samples_split=4,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False)],\n",
       " [\"{'n_estimators': 18}\",\n",
       "  0.8885670731707317,\n",
       "  BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "           bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "           n_estimators=18, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)],\n",
       " [\"{'n_estimators': 4}\",\n",
       "  0.9126524390243902,\n",
       "  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "            learning_rate=1.0, n_estimators=4, random_state=None)],\n",
       " [\"{'weights': 'uniform', 'n_neighbors': 20, 'metric': 'euclidean'}\",\n",
       "  0.931859756097561,\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "             weights='uniform')]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445730624028424"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "gb = GradientBoostingClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "bg = BaggingClassifier()\n",
    "ad = AdaBoostClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test,y_test)\n",
    "predProb = rf.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.6035121963196208 - raw\n",
    "#0.5711820261317555 - StandardScalar\n",
    "#0.6044318818874117 - Standard Scalar without park/water info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723614812347324"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_test,y_test)\n",
    "predProb = gb.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.6867954021859667 - Raw\n",
    "#0.6733643100619126 - Standard Scalar\n",
    "#0.7150969608432872 - Standard Scalar without parks/water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7294858982900289"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.fit(X_train, y_train)\n",
    "bg.score(X_test,y_test)\n",
    "predProb = bg.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.5778244270123619 - Raw\n",
    "#0.6225954160988963 - Standard Scalar\n",
    "#0.6635925230279445 - Standard Scalar without parks/water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067677104152786"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.fit(X_train, y_train)\n",
    "ad.score(X_test,y_test)\n",
    "predProb = ad.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.5726531138364085 - Raw\n",
    "#0.5756229105030342 - Standard Scalar\n",
    "#0.626083878597413 -  Standard Scalar without parks/water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067677104152786"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train, y_train)\n",
    "preProb = kn.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.5726531138364085 - Raw\n",
    "#0.5756229105030342 - Standard Scalar\n",
    "#0.626083878597413 -  Standard Scalar without parks/water"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
