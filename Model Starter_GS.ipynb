{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building Starter\n",
    "\n",
    "Below are all the relevant dataframes\n",
    "\n",
    "Only thing that remains to be done is aggregate for when there are multiple observations for a single trap/day/species  \n",
    "\n",
    "\n",
    "`df_w` include all the aggregated weather  \n",
    "`df_a` includes weather and park/water data (note park/water data are svd features  \n",
    "`df_s` includes all the spray data (so only years 2011/13) with categorically encoded \"spray before\" and \"spray after\" Variables  \n",
    "\n",
    "\n",
    "No train/test splits have been done, but what we discussed was as standard train/test split for the spray data, and 4-fold CV for the other data, split by year (there is a 'yr' column in the dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "with open('allDF.pickle','rb') as f:\n",
    "    allDF = pickle.load(f)\n",
    "    \n",
    "df_w = allDF[0]\n",
    "df_a = allDF[1]\n",
    "df_s = allDF[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NumMosquitos', 'WnvPresent', 'Date', 'Species', 'Trap', 'Location',\n",
       "       'Yr', 'Week', 'Date_end', 'DewPointamax', 'DewPointamin',\n",
       "       'DewPointmean', 'StnPressureamax', 'StnPressureamin', 'StnPressuremean',\n",
       "       'AvgSpeedamax', 'AvgSpeedamin', 'AvgSpeedmean', 'temp_max', 'temp_min',\n",
       "       'temp_avg', 'precip_total', 'precip_avg', 'Park0', 'Park1', 'Park2',\n",
       "       'Park3', 'Park4', 'Park5', 'Water0', 'Water1', 'Water2', 'Water3',\n",
       "       'Water4', 'Water5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['Yr']==2009]\n",
    "train = df[df['Yr']!= 2009]\n",
    "\n",
    "y_train = train['WnvPresent']\n",
    "y_test = test['WnvPresent']\n",
    "\n",
    "toDrop = ['Date','WnvPresent','Location','NumMosquitos', 'Species','Trap','Location','Yr','Date_end',\n",
    "          'DewPointamax', 'DewPointamin','temp_max', 'temp_min',\n",
    "          'Park0', 'Park1', 'Park2','Park3', 'Park4', 'Park5', \n",
    "          'Water0', 'Water1', 'Water2', 'Water3','Water4', 'Water5'\n",
    "         ]\n",
    "X_train0 = train.drop(toDrop, axis = 'columns')\n",
    "#X_train = X_train.iloc[:,4:] # dropping species, trap, date\n",
    "X_test0 = test.drop(toDrop, axis = 'columns')\n",
    "#X_test = X_test.iloc[:,4:] # dropping species, trap, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ss.fit_transform(X_train0)\n",
    "X_test = ss.transform(X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def best_config(model, parameters, X_train, y_train, cv=None, n_jobs = 2):\n",
    "    \"\"\"\n",
    "    A simple GridSearch \n",
    "    Requires: model, parameters, X & y variables\n",
    "    +\n",
    "    \"\"\"\n",
    "    clf = GridSearchCV(model, parameters, cv=cv, verbose=1, n_jobs=n_jobs)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Finished \"+str(model)[0:15])\n",
    "    print('')\n",
    "    best_estimator = clf.best_estimator_ \n",
    "    return [str(clf.best_params_), clf.best_score_,\n",
    "            best_estimator]\n",
    "\n",
    "\n",
    "def best_model(model_list, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Runs all the gridsearchs and produces a list of ALL results, returns only best_classifier\n",
    "    \"\"\"\n",
    "    best_score = 0.0\n",
    "    best_classifier = None\n",
    "    classifiers = []\n",
    "    for name, model, parameters in model_list:\n",
    "        classifiers.append(best_config(model, parameters,\n",
    "                                       X_train,\n",
    "                                       y_train))\n",
    " \n",
    "    for name, score, classifier in classifiers:\n",
    "        if (score > best_score):\n",
    "            best_score = score\n",
    "            best_classifier = [name, classifier]\n",
    "    return best_classifier[1]\n",
    " \n",
    "    \n",
    "    \n",
    "def model_list():\n",
    "    \"\"\"\n",
    "    Generates a list of models & params,\n",
    "    Add more manually, for more options\n",
    "    gb = GradientBoostingClassifier()\n",
    "    rf = RandomForestClassifier()\n",
    "    bg = BaggingClassifier()\n",
    "    ad = AdaBoostClassifier()\n",
    "    knn = KNeighborsClassifier()\n",
    "    \"\"\"\n",
    "    models = []    \n",
    "    \n",
    "    #gradient\n",
    "    gb_tuned_parameters = [{\"n_estimators\": [100 ,250]}]\n",
    "    models.append(['GB', GradientBoostingClassifier(), gb_tuned_parameters])\n",
    " \n",
    "    #random forest\n",
    "    rf_tuned_parameters = [{\"max_depth\": [None]}]\n",
    "    models.append([\"RandomForest\",RandomForestClassifier(n_jobs=-1),rf_tuned_parameters])\n",
    "\n",
    "    #Bagged\n",
    "    bg_tuned_parameters = [{\"n_estimators\": [10, 25]}]\n",
    "    models.append(['GB', BaggingClassifier(), bg_tuned_parameters])\n",
    "\n",
    "    #Ada Model\n",
    "    ad_tuned_parameters = [{\"n_estimators\": [50, 100]}]\n",
    "    models.append(['GB', AdaBoostClassifier(), ad_tuned_parameters])\n",
    "    \n",
    "    \n",
    "    #kNN Model\n",
    "    knn_tuned_parameters = [{\"n_neighbors\": [1, 3, 5, 10, 20], \n",
    "                             'weights':['uniform','distance'],\n",
    "                            'metric':['euclidean','manhattan']}]\n",
    "    models.append([\"kNN\", KNeighborsClassifier(),knn_tuned_parameters])\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished GradientBoostin\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished RandomForestCla\n",
      "\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished BaggingClassifi\n",
      "\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished AdaBoostClassif\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   25.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished KNeighborsClass\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:   40.4s finished\n"
     ]
    }
   ],
   "source": [
    "GS_model = best_model(model_list(),X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='manhattan',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445730624028424"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "gb = GradientBoostingClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "bg = BaggingClassifier()\n",
    "ad = AdaBoostClassifier()\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test,y_test)\n",
    "predProb = rf.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.6035121963196208 - raw\n",
    "#0.5711820261317555 - StandardScalar\n",
    "#0.6044318818874117 - Standard Scalar without park/water info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723614812347324"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(X_train, y_train)\n",
    "gb.score(X_test,y_test)\n",
    "predProb = gb.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.6867954021859667 - Raw\n",
    "#0.6733643100619126 - Standard Scalar\n",
    "#0.7150969608432872 - Standard Scalar without parks/water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7294858982900289"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg.fit(X_train, y_train)\n",
    "bg.score(X_test,y_test)\n",
    "predProb = bg.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.5778244270123619 - Raw\n",
    "#0.6225954160988963 - Standard Scalar\n",
    "#0.6635925230279445 - Standard Scalar without parks/water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067677104152786"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.fit(X_train, y_train)\n",
    "ad.score(X_test,y_test)\n",
    "predProb = ad.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.5726531138364085 - Raw\n",
    "#0.5756229105030342 - Standard Scalar\n",
    "#0.626083878597413 -  Standard Scalar without parks/water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8067677104152786"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier()\n",
    "kn.fit(X_train, y_train)\n",
    "preProb = kn.predict_proba(X_test)\n",
    "roc_auc_score(y_test, predProb[:,1])\n",
    "#0.5726531138364085 - Raw\n",
    "#0.5756229105030342 - Standard Scalar\n",
    "#0.626083878597413 -  Standard Scalar without parks/water"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
